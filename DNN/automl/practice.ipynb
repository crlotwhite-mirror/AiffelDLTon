{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import autokeras as ak\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import preprocess\n",
    "\n",
    "train_df, le = preprocess('../train.csv')\n",
    "\n",
    "x = train_df['conversation'].values\n",
    "y = train_df['class'].values\n",
    "\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=random_state)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T17:21:44.896362800Z",
     "start_time": "2023-07-08T17:20:28.810429600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 06s]\n",
      "val_loss: 1.0211108922958374\n",
      "\n",
      "Best val_loss So Far: 0.8995197415351868\n",
      "Total elapsed time: 00h 00m 45s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/5\n",
      "113/113 [==============================] - 2s 13ms/step - loss: 1.3815 - accuracy: 0.2794\n",
      "Epoch 2/5\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 1.2466 - accuracy: 0.3734\n",
      "Epoch 3/5\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.9024 - accuracy: 0.6010\n",
      "Epoch 4/5\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.6094 - accuracy: 0.7526\n",
      "Epoch 5/5\n",
      "113/113 [==============================] - 1s 12ms/step - loss: 0.4686 - accuracy: 0.8147\n",
      "INFO:tensorflow:Assets written to: .\\auto_model\\best_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: .\\auto_model\\best_model\\assets\n"
     ]
    }
   ],
   "source": [
    "input_node = ak.TextInput()\n",
    "# output_node = ak.TextToIntSequence()(input_node)\n",
    "# output_node = ak.Embedding()(output_node)\n",
    "# output_node = ak.ConvBlock(separable=True)(output_node)\n",
    "output_node = ak.TextBlock()(input_node)\n",
    "output_node = ak.ClassificationHead()(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node,\n",
    "    outputs=output_node,\n",
    "    overwrite=True,\n",
    "    max_trials=5\n",
    ")\n",
    "clf.fit(X_train, y_train, epochs=5)\n",
    "model = clf.export_model()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None,)]                 0         \n",
      "                                                                 \n",
      " expand_last_dim (ExpandLas  (None, 1)                 0         \n",
      " tDim)                                                           \n",
      "                                                                 \n",
      " text_vectorization (TextVe  (None, 64)                0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 64, 128)           640128    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64, 128)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 62, 32)            12320     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 60, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 30, 32)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 28, 32)            3104      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 26, 32)            3104      \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 13, 32)            0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 416)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                6672      \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                544       \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 32)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 132       \n",
      "                                                                 \n",
      " classification_head_1 (Sof  (None, 4)                 0         \n",
      " tmax)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 669108 (2.55 MB)\n",
      "Trainable params: 669108 (2.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T17:29:01.244735100Z",
     "start_time": "2023-07-08T17:29:01.209498800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 4 Complete [00h 00m 00s]\n",
      "\n",
      "Best val_loss So Far: 0.6239032745361328\n",
      "Total elapsed time: 00h 01m 23s\n",
      "\n",
      "Search: Running Trial #5\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "vanilla           |vanilla           |text_block_1/block_type\n",
      "none              |none              |text_block_1/embedding_1/pretraining\n",
      "64                |64                |text_block_1/embedding_1/embedding_dim\n",
      "0.25              |0.25              |text_block_1/embedding_1/dropout\n",
      "5                 |5                 |text_block_1/conv_block_1/kernel_size\n",
      "False             |False             |text_block_1/conv_block_1/separable\n",
      "False             |False             |text_block_1/conv_block_1/max_pooling\n",
      "1                 |1                 |text_block_1/conv_block_1/num_blocks\n",
      "1                 |1                 |text_block_1/conv_block_1/num_layers\n",
      "256               |256               |text_block_1/conv_block_1/filters_0_0\n",
      "512               |512               |text_block_1/conv_block_1/filters_0_1\n",
      "0                 |0                 |text_block_1/conv_block_1/dropout\n",
      "16                |16                |text_block_1/conv_block_1/filters_1_0\n",
      "32                |16                |text_block_1/conv_block_1/filters_1_1\n",
      "0                 |0                 |classification_head_1/dropout\n",
      "adam              |adam              |optimizer\n",
      "0.001             |0.001             |learning_rate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\engine\\tuner.py\", line 91, in _build_and_fit_model\n",
      "    model = self._try_build(trial.hyperparameters)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py\", line 155, in _try_build\n",
      "    model = self._build_hypermodel(hp)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py\", line 146, in _build_hypermodel\n",
      "    model = self.hypermodel.build(hp)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 115, in _build_wrapper\n",
      "    return self._build(hp, *args, **kwargs)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\graph.py\", line 250, in build\n",
      "    outputs = block.build(hp, inputs=temp_inputs)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\engine\\block.py\", line 38, in _build_wrapper\n",
      "    return super()._build_wrapper(hp, *args, **kwargs)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 115, in _build_wrapper\n",
      "    return self._build(hp, *args, **kwargs)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\blocks\\wrapper.py\", line 159, in build\n",
      "    output_node = self._build_block(hp, output_node, block_type)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\blocks\\wrapper.py\", line 165, in _build_block\n",
      "    max_tokens = self.max_tokens or hp.Choice(\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py\", line 295, in Choice\n",
      "    return self._retrieve(hp)\n",
      "  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py\", line 203, in _retrieve\n",
      "    return self.values[hp.name]\n",
      "KeyError: 'text_block_1/max_tokens'\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\engine\\tuner.py\", line 91, in _build_and_fit_model\n    model = self._try_build(trial.hyperparameters)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py\", line 155, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py\", line 146, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 115, in _build_wrapper\n    return self._build(hp, *args, **kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\graph.py\", line 250, in build\n    outputs = block.build(hp, inputs=temp_inputs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\engine\\block.py\", line 38, in _build_wrapper\n    return super()._build_wrapper(hp, *args, **kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 115, in _build_wrapper\n    return self._build(hp, *args, **kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\blocks\\wrapper.py\", line 159, in build\n    output_node = self._build_block(hp, output_node, block_type)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\blocks\\wrapper.py\", line 165, in _build_block\n    max_tokens = self.max_tokens or hp.Choice(\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py\", line 295, in Choice\n    return self._retrieve(hp)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py\", line 203, in _retrieve\n    return self.values[hp.name]\nKeyError: 'text_block_1/max_tokens'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 6\u001B[0m\n\u001B[0;32m      1\u001B[0m clf \u001B[38;5;241m=\u001B[39m ak\u001B[38;5;241m.\u001B[39mTextClassifier(\n\u001B[0;32m      2\u001B[0m     overwrite\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m      3\u001B[0m     max_trials\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m,\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# validation_split=0.15\u001B[39;00m\n\u001B[0;32m      5\u001B[0m )\n\u001B[1;32m----> 6\u001B[0m \u001B[43mclf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\tasks\\text.py:160\u001B[0m, in \u001B[0;36mTextClassifier.fit\u001B[1;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    105\u001B[0m     x\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    111\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    112\u001B[0m ):\n\u001B[0;32m    113\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Search for the best model and hyperparameters for the AutoModel.\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \n\u001B[0;32m    115\u001B[0m \u001B[38;5;124;03m    It will search for the best model based on the performances on\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    158\u001B[0m \u001B[38;5;124;03m            validation loss values and validation metrics values (if applicable).\u001B[39;00m\n\u001B[0;32m    159\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 160\u001B[0m     history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mfit(\n\u001B[0;32m    161\u001B[0m         x\u001B[38;5;241m=\u001B[39mx,\n\u001B[0;32m    162\u001B[0m         y\u001B[38;5;241m=\u001B[39my,\n\u001B[0;32m    163\u001B[0m         epochs\u001B[38;5;241m=\u001B[39mepochs,\n\u001B[0;32m    164\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[0;32m    165\u001B[0m         validation_split\u001B[38;5;241m=\u001B[39mvalidation_split,\n\u001B[0;32m    166\u001B[0m         validation_data\u001B[38;5;241m=\u001B[39mvalidation_data,\n\u001B[0;32m    167\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    168\u001B[0m     )\n\u001B[0;32m    169\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m history\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\auto_model.py:292\u001B[0m, in \u001B[0;36mAutoModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_data \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m validation_split:\n\u001B[0;32m    288\u001B[0m     dataset, validation_data \u001B[38;5;241m=\u001B[39m data_utils\u001B[38;5;241m.\u001B[39msplit_dataset(\n\u001B[0;32m    289\u001B[0m         dataset, validation_split\n\u001B[0;32m    290\u001B[0m     )\n\u001B[1;32m--> 292\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtuner\u001B[38;5;241m.\u001B[39msearch(\n\u001B[0;32m    293\u001B[0m     x\u001B[38;5;241m=\u001B[39mdataset,\n\u001B[0;32m    294\u001B[0m     epochs\u001B[38;5;241m=\u001B[39mepochs,\n\u001B[0;32m    295\u001B[0m     callbacks\u001B[38;5;241m=\u001B[39mcallbacks,\n\u001B[0;32m    296\u001B[0m     validation_data\u001B[38;5;241m=\u001B[39mvalidation_data,\n\u001B[0;32m    297\u001B[0m     validation_split\u001B[38;5;241m=\u001B[39mvalidation_split,\n\u001B[0;32m    298\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    300\u001B[0m )\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m history\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\engine\\tuner.py:193\u001B[0m, in \u001B[0;36mAutoTuner.search\u001B[1;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001B[0m\n\u001B[0;32m    191\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_build(hp)\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mupdate_space(hp)\n\u001B[1;32m--> 193\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39msearch(\n\u001B[0;32m    194\u001B[0m     epochs\u001B[38;5;241m=\u001B[39mepochs, callbacks\u001B[38;5;241m=\u001B[39mnew_callbacks, verbose\u001B[38;5;241m=\u001B[39mverbose, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs\n\u001B[0;32m    195\u001B[0m )\n\u001B[0;32m    197\u001B[0m \u001B[38;5;66;03m# Train the best model use validation data.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;66;03m# Train the best model with enough number of epochs.\u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_split \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m early_stopping_inserted:\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py:231\u001B[0m, in \u001B[0;36mBaseTuner.search\u001B[1;34m(self, *fit_args, **fit_kwargs)\u001B[0m\n\u001B[0;32m    229\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_trial_begin(trial)\n\u001B[0;32m    230\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_run_and_update_trial(trial, \u001B[38;5;241m*\u001B[39mfit_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_kwargs)\n\u001B[1;32m--> 231\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mon_trial_end\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mon_search_end()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py:335\u001B[0m, in \u001B[0;36mBaseTuner.on_trial_end\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m    329\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mon_trial_end\u001B[39m(\u001B[38;5;28mself\u001B[39m, trial):\n\u001B[0;32m    330\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Called at the end of a trial.\u001B[39;00m\n\u001B[0;32m    331\u001B[0m \n\u001B[0;32m    332\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    333\u001B[0m \u001B[38;5;124;03m        trial: A `Trial` instance.\u001B[39;00m\n\u001B[0;32m    334\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 335\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moracle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mend_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    336\u001B[0m     \u001B[38;5;66;03m# Display needs the updated trial scored by the Oracle.\u001B[39;00m\n\u001B[0;32m    337\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_display\u001B[38;5;241m.\u001B[39mon_trial_end(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moracle\u001B[38;5;241m.\u001B[39mget_trial(trial\u001B[38;5;241m.\u001B[39mtrial_id))\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\oracle.py:107\u001B[0m, in \u001B[0;36msynchronized.<locals>.wrapped_func\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    105\u001B[0m     LOCKS[oracle]\u001B[38;5;241m.\u001B[39macquire()\n\u001B[0;32m    106\u001B[0m     THREADS[oracle] \u001B[38;5;241m=\u001B[39m thread_name\n\u001B[1;32m--> 107\u001B[0m ret_val \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    108\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m need_acquire:\n\u001B[0;32m    109\u001B[0m     THREADS[oracle] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\oracle.py:434\u001B[0m, in \u001B[0;36mOracle.end_trial\u001B[1;34m(self, trial)\u001B[0m\n\u001B[0;32m    432\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_retry(trial):\n\u001B[0;32m    433\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mend_order\u001B[38;5;241m.\u001B[39mappend(trial\u001B[38;5;241m.\u001B[39mtrial_id)\n\u001B[1;32m--> 434\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_consecutive_failures\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    436\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_save_trial(trial)\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave()\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\oracle.py:386\u001B[0m, in \u001B[0;36mOracle._check_consecutive_failures\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    384\u001B[0m     consecutive_failures \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m consecutive_failures \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_consecutive_failed_trials:\n\u001B[1;32m--> 386\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    387\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of consecutive failures excceeded the limit \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    388\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mof \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmax_consecutive_failed_trials\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    389\u001B[0m         \u001B[38;5;241m+\u001B[39m trial\u001B[38;5;241m.\u001B[39mmessage\n\u001B[0;32m    390\u001B[0m     )\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Number of consecutive failures excceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 270, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\base_tuner.py\", line 235, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py\", line 287, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\engine\\tuner.py\", line 91, in _build_and_fit_model\n    model = self._try_build(trial.hyperparameters)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py\", line 155, in _try_build\n    model = self._build_hypermodel(hp)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\tuner.py\", line 146, in _build_hypermodel\n    model = self.hypermodel.build(hp)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 115, in _build_wrapper\n    return self._build(hp, *args, **kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\graph.py\", line 250, in build\n    outputs = block.build(hp, inputs=temp_inputs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\engine\\block.py\", line 38, in _build_wrapper\n    return super()._build_wrapper(hp, *args, **kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hypermodel.py\", line 115, in _build_wrapper\n    return self._build(hp, *args, **kwargs)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\blocks\\wrapper.py\", line 159, in build\n    output_node = self._build_block(hp, output_node, block_type)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\autokeras\\blocks\\wrapper.py\", line 165, in _build_block\n    max_tokens = self.max_tokens or hp.Choice(\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py\", line 295, in Choice\n    return self._retrieve(hp)\n  File \"C:\\Users\\tama0\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras_tuner\\engine\\hyperparameters\\hyperparameters.py\", line 203, in _retrieve\n    return self.values[hp.name]\nKeyError: 'text_block_1/max_tokens'\n"
     ]
    }
   ],
   "source": [
    "clf = ak.TextClassifier(\n",
    "    overwrite=True,\n",
    "    max_trials=5,\n",
    "    # validation_split=0.15\n",
    ")\n",
    "clf.fit(X_train, y_train, epochs=5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicted_y = clf.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(clf.evaluate(X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1852, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 4) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filegp2nqoxf.py:15\u001B[0m, in \u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001B[1;34m(iterator)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     14\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m     retval_ \u001B[38;5;241m=\u001B[39m ag__\u001B[38;5;241m.\u001B[39mconverted_call(ag__\u001B[38;5;241m.\u001B[39mld(step_function), (ag__\u001B[38;5;241m.\u001B[39mld(\u001B[38;5;28mself\u001B[39m), ag__\u001B[38;5;241m.\u001B[39mld(iterator)), \u001B[38;5;28;01mNone\u001B[39;00m, fscope)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m:\n\u001B[0;32m     17\u001B[0m     do_return \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mValueError\u001B[0m: in user code:\n\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1972, in test_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1956, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1944, in run_step  **\n        outputs = model.test_step(data)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1852, in test_step\n        self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"C:\\Users\\tama0\\anaconda3\\envs\\dlton210\\lib\\site-packages\\keras\\src\\backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 4) are incompatible\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T17:29:06.009616300Z",
     "start_time": "2023-07-08T17:29:05.896100800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 2, 2, ..., 2, 0, 1])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-08T17:29:46.683888400Z",
     "start_time": "2023-07-08T17:29:46.678888200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fuck\n",
    "# import tensorflow as tf\n",
    "# tf.keras.backend.clear_session()\n",
    "# model = tf.keras.models.load_model('./auto_model/best_model')\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, epochs=100, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_test = ['''우리팀에서 다른팀으로 갈 사람 없나? 그럼 영지씨가 가는건 어때?\n",
    "네? 제가요?\n",
    "그렇지? 2달만 파견 잘 갔다오면 승진이야.\n",
    "네? 저는 별로 가고 싶지 않습니다.\n",
    "여기 있는 모든사람도 가기 싫어해. 그러니까 막내인 영지씨가 가는게 맞지\n",
    "정말 죄송합니다. 저는 못갑니다.\n",
    "장난해? 모두를 위해 영지씨가 희생하는게 싫어?\n",
    "네. 부당한 방법으로 가는 것 같습니다.\n",
    "영지씨 안가면 회사생활 오래 못할 것 같은데 그래도 안갈거야? 안가면 지옥일텐데.\n",
    "그래도 이 방법은 아닌 것 같습니다. 죄송합니다.''']\n",
    "\n",
    "X_test = np.array(X_test)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_y = le.transform([\"직장 내 괴롭힘 대화\"])\n",
    "test_y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "pred_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "https://dacon.io/codeshare/1843\n",
    "https://dacon.io/competitions/official/235658/codeshare/2246"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
