{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09d4f671-ac88-4805-94f9-34f3f2760e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "09d4f671-ac88-4805-94f9-34f3f2760e5b",
    "outputId": "c8bac1ff-3729-4b32-c45d-88647eacd993"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu117\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchmetrics in /opt/conda/lib/python3.10/site-packages (1.0.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (2.0.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (23.0)\n",
      "Requirement already satisfied: numpy>1.20.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (1.24.3)\n",
      "Requirement already satisfied: lightning-utilities>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from torchmetrics) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from lightning-utilities>=0.7.0->torchmetrics) (4.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: optuna in /opt/conda/lib/python3.10/site-packages (3.2.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (1.11.1)\n",
      "Requirement already satisfied: cmaes>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from optuna) (0.9.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (2.0.18)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.10/site-packages (from optuna) (6.7.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optuna) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: Mako in /opt/conda/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/conda/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: koeda in /opt/conda/lib/python3.10/site-packages (0.0.4)\n",
      "Requirement already satisfied: tweepy==3.10.0 in /opt/conda/lib/python3.10/site-packages (from koeda) (3.10.0)\n",
      "Requirement already satisfied: konlpy>=0.5.2 in /opt/conda/lib/python3.10/site-packages (from koeda) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /opt/conda/lib/python3.10/site-packages (from koeda) (1.24.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from tweepy==3.10.0->koeda) (1.16.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tweepy==3.10.0->koeda) (1.3.1)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.10/site-packages (from tweepy==3.10.0->koeda) (2.29.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from konlpy>=0.5.2->koeda) (1.4.1)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from konlpy>=0.5.2->koeda) (4.9.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy>=0.5.2->koeda) (23.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->tweepy==3.10.0->koeda) (3.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (2023.5.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from requests[socks]>=2.11.1->tweepy==3.10.0->koeda) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mmecab-ko is already installed\n",
      "mecab-ko-dic is already installed\n",
      "mecab-python is already installed\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --index-url https://download.pytorch.org/whl/cu117\n",
    "!pip install transformers\n",
    "!pip install torchmetrics\n",
    "!pip install optuna\n",
    "!pip install koeda\n",
    "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd72aea8-834c-4cdc-a096-5d4a163552b8",
   "metadata": {
    "id": "bd72aea8-834c-4cdc-a096-5d4a163552b8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from koeda import EDA\n",
    "from konlpy.tag import Mecab\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import optuna\n",
    "import joblib\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "import gc\n",
    "\n",
    "## GPU 확인\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01ee152a-ade2-4aab-af0c-ee53146d58fd",
   "metadata": {
    "id": "01ee152a-ade2-4aab-af0c-ee53146d58fd"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_len, test_csv='output.csv'):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.test = pd.read_csv(test_csv)\n",
    "        self.test = self.test[['text', 'class']]\n",
    "\n",
    "        self.test = self.test.fillna(value=' ')\n",
    "        self.test = self.test.dropna()\n",
    "\n",
    "        self.__data_augmentation()\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(self.data['class'])\n",
    "        self.data['class'] = self.le.transform(self.data['class'])\n",
    "\n",
    "        # Tokenization\n",
    "        self.data['conversation'] = \"[CLS] \" + self.data['conversation'] + \" [SEP]\"\n",
    "        tokenized_texts = [self.tokenizer.tokenize(s) for s in self.data['conversation']]\n",
    "\n",
    "        # Convert tokens to IDs, pad sequences and create attention masks\n",
    "        input_ids = [self.tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "        input_ids = pad_sequences(input_ids, maxlen=self.max_len, dtype='long', truncating='post', padding='post')\n",
    "        attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n",
    "\n",
    "        # Split into training and validation sets\n",
    "        train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, self.data['class'].values, random_state=42, test_size=0.1)\n",
    "        train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42, test_size=0.1)\n",
    "\n",
    "        # Convert to tensors\n",
    "        self.train_inputs = torch.tensor(train_inputs)\n",
    "        self.train_labels = torch.tensor(train_labels)\n",
    "        self.train_masks = torch.tensor(train_masks)\n",
    "        self.validation_inputs = torch.tensor(validation_inputs)\n",
    "        self.validation_labels = torch.tensor(validation_labels)\n",
    "        self.validation_masks = torch.tensor(validation_masks)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'train_inputs': self.train_inputs[idx],\n",
    "            'train_labels': self.train_labels[idx],\n",
    "            'train_masks': self.train_masks[idx],\n",
    "            'validation_inputs': self.validation_inputs[idx],\n",
    "            'validation_labels': self.validation_labels[idx],\n",
    "            'validation_masks': self.validation_masks[idx],\n",
    "        }\n",
    "\n",
    "    def get_dataloader(self, batch_size):\n",
    "        train_data = TensorDataset(self.train_inputs, self.train_masks, self.train_labels)\n",
    "        train_sampler = RandomSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "        validation_data = TensorDataset(self.validation_inputs, self.validation_masks, self.validation_labels)\n",
    "        validation_sampler = SequentialSampler(validation_data)\n",
    "        validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "        return train_dataloader, validation_dataloader\n",
    "\n",
    "    def __data_augmentation(self):\n",
    "        augmenter = EDA(morpheme_analyzer=Mecab(), alpha_sr=0.3, alpha_ri=0.3, alpha_rs=0.3, prob_rd=0.3)\n",
    "        p = (0.4, 0.4, 0.4, 0.4)\n",
    "        \n",
    "        # 랜덤하게 행 선택 (예: 전체 행의 20%를 선택)\n",
    "        random_indices = np.random.choice(self.data.index, size=int(len(self.data) * 0.3), replace=False)\n",
    "\n",
    "        # 선택된 행에 대해 Random swap 함수 적용\n",
    "        augmented_rows = self.data.loc[random_indices, 'conversation'].apply(lambda text: augmenter(text, p, 1))\n",
    "\n",
    "        # 증강된 데이터를 복사하고, 'text' 열에 증강된 텍스트를 삽입\n",
    "        new_rows = self.data.loc[random_indices].copy()\n",
    "        new_rows['conversation'] = augmented_rows\n",
    "\n",
    "        self.data = pd.concat([self.data, new_rows])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac67a3e-d1da-4433-b95d-018facd36b04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ac67a3e-d1da-4433-b95d-018facd36b04",
    "outputId": "c51f2fc3-68a3-4650-98cb-217acb34467a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "#GPU 체크 및 할당\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('No GPU available, using the CPU instead.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f80b58e3-d483-41c3-9b8b-221aa4960ff4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c4dd5cc7971c4389832d8db460b852ab",
      "554e4402d5d646bfb729c37486884f1d",
      "5f83f543780245a2b0ce95946d9133be",
      "1bae8910f4af4307a74dc1940c3661bd",
      "dba651b0d56f4e12813113441f738078",
      "e4da1f60c4774e848af9c216311b01ca",
      "ee7f43477d8b4b4dbe575374bb84b0b9",
      "14aef3f10ed143a3bd323cdd9144dd36",
      "ef9f7c22c0b74b22b92d9fd3c0431d60",
      "c5091dc44fa5458b9f978bff41749211",
      "4d46fd77ede4413b981da4bd3c4170d6",
      "be30306034f74401bbc63838dfbdec25",
      "f91177cd77b842629b8cad01aa9cca86",
      "367b0e70c9054897bee8dbbdefa7d458",
      "ccd64d3903ad4a2abaad007c62500b29",
      "5bcbc77eb62f4e018be363fea340bd63",
      "1451f17a2d214509a61e74020a369fa5",
      "f6673f77ca114875b7fee044997fce3f",
      "6dad7fced7364d60b55e40251894bbad",
      "7b691a12baad4d4f8a74f0013aaa83e2",
      "d5683d78621549c598fbe515954bb6e7",
      "f9988c3a1eca473ab48e78c68ec9e39f",
      "1ef454a6b37b42f287520ac7ea696412",
      "dd3c89faa1214225b6641a0c460dd507",
      "2454a28be8894e13ad5cc49f19c96672",
      "e748e64b70064f91aac0f4a2cef596ea",
      "8f307101ebef4347abb828584e078be7",
      "80cc564331444369b8726276651ac2bc",
      "a2d99f55e33f4d7f81f2228d16dc9b3d",
      "55679d50986f4b208fff205c6ab1f38e",
      "33c5e76006a6497d8a7741d3f491af44",
      "9fc6c841b2344cd19471d49036ca5596",
      "e67e945fecdd49d8a2960e4e62b0eee2",
      "8908c0da2b5241568e744bfa2a6a1551",
      "95d0acf0918549f0a4aa2045485a187b",
      "d3de772b7be54e5ab789544ef908927e",
      "b0bb41b2bfc045a282fa333c86f29bcb",
      "759287607f994e3ab5d4da9f15b28581",
      "2752085e96a14bd7aa4156f40d4653e4",
      "016a4e4358ba4297bfacd0a3f8a67ff2",
      "18892dcdc2434cffa04e6e34490f222b",
      "5d53e961b2754ca49dbc7f319ed1c3dd",
      "3c23ce2f780646f98b192f3b67c0e144",
      "f5f8c005fa3a4bf0a13ddb44fb170e3a"
     ]
    },
    "id": "f80b58e3-d483-41c3-9b8b-221aa4960ff4",
    "outputId": "a740b77d-2dcf-4fc2-8cc7-a20d0fb08c01"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(42000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('kykim/bert-kor-base', do_lower_case=False)\n",
    "\n",
    "# BERT Model\n",
    "model = BertForSequenceClassification.from_pretrained('kykim/bert-kor-base', num_labels=4)\n",
    "model.cuda()\n",
    "\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6543e1e6-1c32-41c2-9a82-26d300daacbd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6543e1e6-1c32-41c2-9a82-26d300daacbd",
    "outputId": "c81f48a8-3110-404d-8293-cb858d679e8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118300420"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "492795d0-0992-4787-89d2-cf5839b067c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = CustomDataset(\"train.csv\", tokenizer, max_len=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe0a3c7c-19f4-4461-8be7-c35ac4bf337b",
   "metadata": {
    "id": "fe0a3c7c-19f4-4461-8be7-c35ac4bf337b"
   },
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, optimizer, scheduler, t0):\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask,\n",
    "                        labels=b_labels)\n",
    "\n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "623f96d4-77a6-474d-bc0e-ab8f4ec0b899",
   "metadata": {
    "id": "623f96d4-77a6-474d-bc0e-ab8f4ec0b899"
   },
   "outputs": [],
   "source": [
    "def val(model, validation_dataloader):\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in validation_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():\n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids,\n",
    "                            token_type_ids=None,\n",
    "                            attention_mask=b_input_mask)\n",
    "\n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    return eval_accuracy, nb_eval_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe49e5c1-9941-49fa-b82d-ed2f755ecf14",
   "metadata": {
    "id": "fe49e5c1-9941-49fa-b82d-ed2f755ecf14"
   },
   "outputs": [],
   "source": [
    "# accuracy 와 시간 표시함수 정의\n",
    "# 정확도 계산 함수\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "def train_bert(trial):\n",
    "    cfg = {\n",
    "        'epochs': trial.suggest_int('epochs', 3, 5, 1), # 4,\n",
    "        'lr': trial.suggest_loguniform('lr', 1e-5, 2e-5), #2e-5,\n",
    "        'eps': 1e-8,\n",
    "        'batch_size': trial.suggest_categorical('batch_size',[8, 16, 32]), # 32,\n",
    "        'seed_val':42,\n",
    "    }\n",
    "    global model\n",
    "    global tokenizer\n",
    "    global dataset\n",
    "\n",
    "    # DataLoader\n",
    "    train_dataloader, validation_dataloader = dataset.get_dataloader(batch_size=cfg['batch_size'])\n",
    "\n",
    "    # transformers에서 제공하는 옵티마이저 중 AdamW를 사용\n",
    "    # 총 훈련 스텝은 이터레이션 * 에폭 수로 설정\n",
    "    # lr 스케쥴러도 transformers에서 제공하는것을 사용\n",
    "    print('schedule start')\n",
    "    #옵티마이저 설정\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr=cfg['lr'], # 학습률\n",
    "                      eps=cfg['eps'] # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "    # 총 훈련 스텝\n",
    "    total_steps = len(train_dataloader) * cfg['epochs']\n",
    "\n",
    "    # lr 조금씩 감소시키는 스케줄러\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps = 0,\n",
    "                                                num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "    # gradient update는 명시적으로 하지 않고 위에서 로드한 optimizer를 활용\n",
    "    # 재현을 위해 랜덤시드 고정\n",
    "\n",
    "    random.seed(cfg['seed_val'])\n",
    "    np.random.seed(cfg['seed_val'])\n",
    "    torch.manual_seed(cfg['seed_val'])\n",
    "    torch.cuda.manual_seed_all(cfg['seed_val'])\n",
    "\n",
    "    # 그래디언트 초기화\n",
    "    model.zero_grad()\n",
    "\n",
    "    # 에폭만큼 반복\n",
    "    for epoch_i in range(0, cfg['epochs']):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, cfg['epochs']))\n",
    "        print('Training...')\n",
    "\n",
    "        # 시작 시간 설정\n",
    "        t0 = time.time()\n",
    "\n",
    "        # 학습 함수\n",
    "        total_loss = train(model, train_dataloader, optimizer, scheduler, t0)\n",
    "\n",
    "        # 평균 로스 계산\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        # ===================================================================== #\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        #시작 시간 설정\n",
    "        t0 = time.time()\n",
    "\n",
    "        # 평가 함수 실행\n",
    "        eval_accuracy, nb_eval_steps = val(model, validation_dataloader)\n",
    "\n",
    "        print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6050961-2b4c-47ec-851b-155cd29f1940",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e6050961-2b4c-47ec-851b-155cd29f1940",
    "outputId": "c6224136-5dab-4d65-c644-abbf8e21aca5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-07-10 19:12:33,113] A new study created in memory with name: no-name-71746e60-6ec4-4849-9bb0-8e94a85e49c2\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.58\n",
      "  Training epcoh took: 0:01:32\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.25\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.89\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 19:17:16,529] Trial 0 failed with parameters: {'epochs': 3, 'lr': 1.0092620562972524e-05, 'batch_size': 16} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 19:17:16,529] Trial 0 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.91\n",
      "  Validation took: 0:00:03\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:25.\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:26.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:25.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 19:22:23,625] Trial 1 failed with parameters: {'epochs': 3, 'lr': 1.8395894392247034e-05, 'batch_size': 8} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 19:22:23,625] Trial 1 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:04\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:27\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 19:26:52,993] Trial 2 failed with parameters: {'epochs': 3, 'lr': 1.845997183098764e-05, 'batch_size': 32} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 19:26:52,994] Trial 2 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:26.\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:25.\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:26.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 19:32:00,232] Trial 3 failed with parameters: {'epochs': 3, 'lr': 1.3966651345707101e-05, 'batch_size': 8} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 19:32:00,233] Trial 3 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:04\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 19:38:16,744] Trial 4 failed with parameters: {'epochs': 4, 'lr': 1.4068825606435588e-05, 'batch_size': 16} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 19:38:16,745] Trial 4 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 19:44:33,048] Trial 5 failed with parameters: {'epochs': 4, 'lr': 1.6834129012468502e-05, 'batch_size': 16} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 19:44:33,049] Trial 5 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 19:49:15,276] Trial 6 failed with parameters: {'epochs': 3, 'lr': 1.0164449333108146e-05, 'batch_size': 16} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 19:49:15,277] Trial 6 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:25.\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:25.\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:26.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  Validation took: 0:00:04\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "  Batch   500  of    578.    Elapsed: 0:01:26.\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:39\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 19:56:04,786] Trial 7 failed with parameters: {'epochs': 4, 'lr': 1.3224444147881717e-05, 'batch_size': 8} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 19:56:04,787] Trial 7 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:04\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:26\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 20:03:31,997] Trial 8 failed with parameters: {'epochs': 5, 'lr': 1.5203784162009396e-05, 'batch_size': 32} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 20:03:31,998] Trial 8 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.94\n",
      "  Validation took: 0:00:03\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.05\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 4 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 5 / 5 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2023-07-10 20:11:22,080] Trial 9 failed with parameters: {'epochs': 5, 'lr': 1.843052246404542e-05, 'batch_size': 16} because of the following error: The value None could not be cast to float..\n",
      "[W 2023-07-10 20:11:22,081] Trial 9 failed with value None.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Accuracy: 0.94\n",
      "  Validation took: 0:00:03\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./bert_optuna.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컴퓨터 사양에 자신이 없다면 실행하지 말 것\n",
    "study = optuna.create_study(sampler=optuna.samplers.TPESampler(), direction='maximize')\n",
    "\n",
    "# https://optuna.readthedocs.io/en/stable/faq.html#how-do-i-avoid-running-out-of-memory-oom-when-optimizing-studies\n",
    "study.optimize(train_bert, n_trials=10, gc_after_trial=True)\n",
    "joblib.dump(study, './bert_optuna.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a3df86e-1d9d-4f8a-bde9-9145b21d3e10",
   "metadata": {
    "id": "2a3df86e-1d9d-4f8a-bde9-9145b21d3e10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>value</th>\n",
       "      <th>duration</th>\n",
       "      <th>params_batch_size</th>\n",
       "      <th>params_epochs</th>\n",
       "      <th>params_lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0 days 00:04:43.415155</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>0 days 00:05:06.951276</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>0 days 00:04:29.221624</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>0 days 00:05:07.093242</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>0 days 00:06:16.367611</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number value               duration  params_batch_size  params_epochs  \\\n",
       "0       0  None 0 days 00:04:43.415155                 16              3   \n",
       "1       1  None 0 days 00:05:06.951276                  8              3   \n",
       "2       2  None 0 days 00:04:29.221624                 32              3   \n",
       "3       3  None 0 days 00:05:07.093242                  8              3   \n",
       "4       4  None 0 days 00:06:16.367611                 16              4   \n",
       "\n",
       "   params_lr  \n",
       "0   0.000010  \n",
       "1   0.000018  \n",
       "2   0.000018  \n",
       "3   0.000014  \n",
       "4   0.000014  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "study = joblib.load('./bert_optuna.pkl')\n",
    "df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d585a821-39fd-4600-844b-607754863029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 파라미터로 함수 재정의\n",
    "def train_bert():\n",
    "    cfg = {\n",
    "        'epochs': 3, # 4,\n",
    "        'lr': 0.00001, #2e-5,\n",
    "        'eps': 1e-8,\n",
    "        'batch_size': 16, # 32,\n",
    "        'seed_val':42,\n",
    "    }\n",
    "    global model\n",
    "    global tokenizer\n",
    "    global dataset\n",
    "\n",
    "    # DataLoader\n",
    "    train_dataloader, validation_dataloader = dataset.get_dataloader(batch_size=cfg['batch_size'])\n",
    "\n",
    "    # transformers에서 제공하는 옵티마이저 중 AdamW를 사용\n",
    "    # 총 훈련 스텝은 이터레이션 * 에폭 수로 설정\n",
    "    # lr 스케쥴러도 transformers에서 제공하는것을 사용\n",
    "    print('schedule start')\n",
    "    #옵티마이저 설정\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                      lr=cfg['lr'], # 학습률\n",
    "                      eps=cfg['eps'] # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "                    )\n",
    "\n",
    "\n",
    "\n",
    "    # 총 훈련 스텝\n",
    "    total_steps = len(train_dataloader) * cfg['epochs']\n",
    "\n",
    "    # lr 조금씩 감소시키는 스케줄러\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps = 0,\n",
    "                                                num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "    # gradient update는 명시적으로 하지 않고 위에서 로드한 optimizer를 활용\n",
    "    # 재현을 위해 랜덤시드 고정\n",
    "\n",
    "    random.seed(cfg['seed_val'])\n",
    "    np.random.seed(cfg['seed_val'])\n",
    "    torch.manual_seed(cfg['seed_val'])\n",
    "    torch.cuda.manual_seed_all(cfg['seed_val'])\n",
    "\n",
    "    # 그래디언트 초기화\n",
    "    model.zero_grad()\n",
    "\n",
    "    # 에폭만큼 반복\n",
    "    for epoch_i in range(0, cfg['epochs']):\n",
    "        print(\"\")\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, cfg['epochs']))\n",
    "        print('Training...')\n",
    "\n",
    "        # 시작 시간 설정\n",
    "        t0 = time.time()\n",
    "\n",
    "        # 학습 함수\n",
    "        total_loss = train(model, train_dataloader, optimizer, scheduler, t0)\n",
    "\n",
    "        # 평균 로스 계산\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "        print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        # ===================================================================== #\n",
    "        print(\"\")\n",
    "        print(\"Running Validation...\")\n",
    "\n",
    "        #시작 시간 설정\n",
    "        t0 = time.time()\n",
    "\n",
    "        # 평가 함수 실행\n",
    "        eval_accuracy, nb_eval_steps = val(model, validation_dataloader)\n",
    "\n",
    "        print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "        print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "52afe574-a821-497b-81c3-c933fc1b6eb8",
   "metadata": {
    "id": "52afe574-a821-497b-81c3-c933fc1b6eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train start\n",
      "schedule start\n",
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Average training loss: 0.77\n",
      "  Training epcoh took: 0:01:30\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.93\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:01:31\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "  Validation took: 0:00:03\n",
      "\n",
      "Training complete!\n",
      "\n",
      "\n",
      "\n",
      " 0:04:42.265108\n"
     ]
    }
   ],
   "source": [
    "## 기본 학습 루틴\n",
    "print('train start')\n",
    "\n",
    "# 학습 총 시간 계산을 위한 datetime\n",
    "sstart = datetime.datetime.now()\n",
    "\n",
    "train_bert()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "print(\"\")\n",
    "\n",
    "print('\\n\\n', datetime.datetime.now() - sstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "07e42503-b627-4daf-a943-2b59d5b7347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 생성\n",
    "test = pd.read_csv('output.csv')\n",
    "test = test[['text', 'class']]\n",
    "\n",
    "test = test.fillna(value=' ')\n",
    "test = test.dropna()\n",
    "\n",
    "sentences = test['text']\n",
    "sentences = [\"[CLS] \" + str(sentence) + \" [SEP]\" for sentence in sentences]\n",
    "test['class'] = dataset.le.transform(test['class'])\n",
    "labels = test['class'].values\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
    "input_ids = pad_sequences(input_ids, maxlen=128, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "attention_masks = []\n",
    "for seq in input_ids:\n",
    "    seq_mask = [float(i>0) for i in seq]\n",
    "    attention_masks.append(seq_mask)\n",
    "\n",
    "test_inputs = torch.tensor(input_ids)\n",
    "test_labels = torch.tensor(labels)\n",
    "test_masks = torch.tensor(attention_masks)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "223ce6f2-7302-422a-abe3-8f6e8637fdcc",
   "metadata": {
    "id": "223ce6f2-7302-422a-abe3-8f6e8637fdcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.87\n",
      "F1 Score: 0.87\n",
      "Precision: 0.87\n",
      "Recall: 0.87\n",
      "ROC AUC: 0.91\n",
      "Test took: 0:00:01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "\n",
    "# 시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.eval()\n",
    "\n",
    "# 변수 초기화\n",
    "eval_loss, eval_accuracy = 0, 0\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "# F1 Score 초기화\n",
    "preds = []\n",
    "true = []\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # 경과 정보 표시\n",
    "    if step % 100 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=b_input_mask)\n",
    "    \n",
    "    # 로스 구함\n",
    "    logits = outputs[0]\n",
    "\n",
    "    # CPU로 데이터 이동\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "    eval_accuracy += tmp_eval_accuracy\n",
    "    nb_eval_steps += 1\n",
    "\n",
    "    # F1 Score를 위해 예측값과 실제값을 저장\n",
    "    preds.append(np.argmax(logits, axis=1))\n",
    "    true.append(label_ids)\n",
    "\n",
    "# Accuracy 출력\n",
    "print(\"\")\n",
    "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "\n",
    "# F1 Score, Precision, Recall 출력\n",
    "# Predictions와 labels이 nested lists로 저장되므로 flatten하여 계산\n",
    "preds = [p for sublist in preds for p in sublist]\n",
    "true = [t for sublist in true for t in sublist]\n",
    "print(\"F1 Score: {0:.2f}\".format(f1_score(true, preds, average='weighted')))\n",
    "print(\"Precision: {0:.2f}\".format(precision_score(true, preds, average='weighted')))\n",
    "print(\"Recall: {0:.2f}\".format(recall_score(true, preds, average='weighted')))\n",
    "\n",
    "# ROC AUC\n",
    "num_classes = len(np.unique(true)) # 클래스 수 계산\n",
    "true_bin = label_binarize(true, classes=list(range(num_classes))) # 실제 레이블 이진화\n",
    "preds_bin = label_binarize(preds, classes=list(range(num_classes))) # 예측 레이블 이진화\n",
    "roc_auc = roc_auc_score(true_bin, preds_bin, average='weighted') # 각 클래스에 대한 ROC AUC를 계산하고 가중 평균\n",
    "print(\"ROC AUC: {0:.2f}\".format(roc_auc))\n",
    "\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "016a4e4358ba4297bfacd0a3f8a67ff2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1451f17a2d214509a61e74020a369fa5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14aef3f10ed143a3bd323cdd9144dd36": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "18892dcdc2434cffa04e6e34490f222b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bae8910f4af4307a74dc1940c3661bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c5091dc44fa5458b9f978bff41749211",
      "placeholder": "​",
      "style": "IPY_MODEL_4d46fd77ede4413b981da4bd3c4170d6",
      "value": " 344k/344k [00:00&lt;00:00, 1.27MB/s]"
     }
    },
    "1ef454a6b37b42f287520ac7ea696412": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dd3c89faa1214225b6641a0c460dd507",
       "IPY_MODEL_2454a28be8894e13ad5cc49f19c96672",
       "IPY_MODEL_e748e64b70064f91aac0f4a2cef596ea"
      ],
      "layout": "IPY_MODEL_8f307101ebef4347abb828584e078be7"
     }
    },
    "2454a28be8894e13ad5cc49f19c96672": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55679d50986f4b208fff205c6ab1f38e",
      "max": 725,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_33c5e76006a6497d8a7741d3f491af44",
      "value": 725
     }
    },
    "2752085e96a14bd7aa4156f40d4653e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "33c5e76006a6497d8a7741d3f491af44": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "367b0e70c9054897bee8dbbdefa7d458": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6dad7fced7364d60b55e40251894bbad",
      "max": 80,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7b691a12baad4d4f8a74f0013aaa83e2",
      "value": 80
     }
    },
    "3c23ce2f780646f98b192f3b67c0e144": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d46fd77ede4413b981da4bd3c4170d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "554e4402d5d646bfb729c37486884f1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4da1f60c4774e848af9c216311b01ca",
      "placeholder": "​",
      "style": "IPY_MODEL_ee7f43477d8b4b4dbe575374bb84b0b9",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "55679d50986f4b208fff205c6ab1f38e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5bcbc77eb62f4e018be363fea340bd63": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d53e961b2754ca49dbc7f319ed1c3dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5f83f543780245a2b0ce95946d9133be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14aef3f10ed143a3bd323cdd9144dd36",
      "max": 344259,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ef9f7c22c0b74b22b92d9fd3c0431d60",
      "value": 344259
     }
    },
    "6dad7fced7364d60b55e40251894bbad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "759287607f994e3ab5d4da9f15b28581": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7b691a12baad4d4f8a74f0013aaa83e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "80cc564331444369b8726276651ac2bc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8908c0da2b5241568e744bfa2a6a1551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_95d0acf0918549f0a4aa2045485a187b",
       "IPY_MODEL_d3de772b7be54e5ab789544ef908927e",
       "IPY_MODEL_b0bb41b2bfc045a282fa333c86f29bcb"
      ],
      "layout": "IPY_MODEL_759287607f994e3ab5d4da9f15b28581"
     }
    },
    "8f307101ebef4347abb828584e078be7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95d0acf0918549f0a4aa2045485a187b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2752085e96a14bd7aa4156f40d4653e4",
      "placeholder": "​",
      "style": "IPY_MODEL_016a4e4358ba4297bfacd0a3f8a67ff2",
      "value": "Downloading pytorch_model.bin: 100%"
     }
    },
    "9fc6c841b2344cd19471d49036ca5596": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2d99f55e33f4d7f81f2228d16dc9b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0bb41b2bfc045a282fa333c86f29bcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c23ce2f780646f98b192f3b67c0e144",
      "placeholder": "​",
      "style": "IPY_MODEL_f5f8c005fa3a4bf0a13ddb44fb170e3a",
      "value": " 476M/476M [00:11&lt;00:00, 43.3MB/s]"
     }
    },
    "be30306034f74401bbc63838dfbdec25": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f91177cd77b842629b8cad01aa9cca86",
       "IPY_MODEL_367b0e70c9054897bee8dbbdefa7d458",
       "IPY_MODEL_ccd64d3903ad4a2abaad007c62500b29"
      ],
      "layout": "IPY_MODEL_5bcbc77eb62f4e018be363fea340bd63"
     }
    },
    "c4dd5cc7971c4389832d8db460b852ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_554e4402d5d646bfb729c37486884f1d",
       "IPY_MODEL_5f83f543780245a2b0ce95946d9133be",
       "IPY_MODEL_1bae8910f4af4307a74dc1940c3661bd"
      ],
      "layout": "IPY_MODEL_dba651b0d56f4e12813113441f738078"
     }
    },
    "c5091dc44fa5458b9f978bff41749211": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccd64d3903ad4a2abaad007c62500b29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d5683d78621549c598fbe515954bb6e7",
      "placeholder": "​",
      "style": "IPY_MODEL_f9988c3a1eca473ab48e78c68ec9e39f",
      "value": " 80.0/80.0 [00:00&lt;00:00, 3.16kB/s]"
     }
    },
    "d3de772b7be54e5ab789544ef908927e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_18892dcdc2434cffa04e6e34490f222b",
      "max": 475782997,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5d53e961b2754ca49dbc7f319ed1c3dd",
      "value": 475782997
     }
    },
    "d5683d78621549c598fbe515954bb6e7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dba651b0d56f4e12813113441f738078": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dd3c89faa1214225b6641a0c460dd507": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80cc564331444369b8726276651ac2bc",
      "placeholder": "​",
      "style": "IPY_MODEL_a2d99f55e33f4d7f81f2228d16dc9b3d",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "e4da1f60c4774e848af9c216311b01ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e67e945fecdd49d8a2960e4e62b0eee2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e748e64b70064f91aac0f4a2cef596ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fc6c841b2344cd19471d49036ca5596",
      "placeholder": "​",
      "style": "IPY_MODEL_e67e945fecdd49d8a2960e4e62b0eee2",
      "value": " 725/725 [00:00&lt;00:00, 15.8kB/s]"
     }
    },
    "ee7f43477d8b4b4dbe575374bb84b0b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ef9f7c22c0b74b22b92d9fd3c0431d60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f5f8c005fa3a4bf0a13ddb44fb170e3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6673f77ca114875b7fee044997fce3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f91177cd77b842629b8cad01aa9cca86": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1451f17a2d214509a61e74020a369fa5",
      "placeholder": "​",
      "style": "IPY_MODEL_f6673f77ca114875b7fee044997fce3f",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "f9988c3a1eca473ab48e78c68ec9e39f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
